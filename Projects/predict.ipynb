{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5a7392-53c4-4738-818e-f13495ac5470",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MemoryAugmentedEncoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46f8fd07c202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMemoryAugmentedEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMeshedDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScaledDotProductAttentionMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MemoryAugmentedEncoder'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from data import ImageDetectionsField, TextField, RawField\n",
    "from data import COCO, DataLoader\n",
    "import evaluation\n",
    "from models.transformer import Transformer, MemoryAugmentedEncoder, MeshedDecoder, ScaledDotProductAttentionMemory\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622d82a2-3004-4aa1-b9f2-5b0365c83942",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41cf00e-dbda-4ee4-bc06-77d60cc22a4d",
   "metadata": {},
   "source": [
    "### predict the test set of artpedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb247fd-ec6a-4ef2-b4b8-8f08fbceb89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_captions(model, dataloader, text_field, mode = \"multiple\"):\n",
    "    import itertools\n",
    "    model.eval()\n",
    "    gen = {}\n",
    "    gts = {}\n",
    "    with tqdm(desc='Evaluation', unit='it', total=len(dataloader)) as pbar:\n",
    "        for it, (images, caps_gt) in enumerate(iter(dataloader)):\n",
    "            print('-'*10 + f\"the {it}the iteration\" + '-'*10)\n",
    "            images = torch.rand(1,50,2048)\n",
    "            images = images.to(device)\n",
    "            with torch.no_grad():\n",
    "                out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 5, out_size=1)\n",
    "            caps_gen = text_field.decode(out, join_words=False)\n",
    "            for i, (gts_i, gen_i) in enumerate(zip(caps_gt, caps_gen)):\n",
    "                gen_i = ' '.join([k for k, g in itertools.groupby(gen_i)])\n",
    "                gen['%d_%d' % (it, i)] = [gen_i.strip(), ]\n",
    "                if mode == \"single\":\n",
    "                    gts['%d_%d' % (it, i)] = [gts_i[0]]\n",
    "                elif mode == \"multiple\":\n",
    "                    gts['%d_%d' % (it, i)] = gts_i\n",
    "            pbar.update()\n",
    "    \n",
    "    gts = evaluation.PTBTokenizer.tokenize(gts)\n",
    "    gen = evaluation.PTBTokenizer.tokenize(gen)\n",
    "    scores, _ = evaluation.compute_scores(gts, gen)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96406ca3-2dc1-496f-b886-2cb99cf84a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meshed-Memory Transformer Evaluation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Meshed-Memory Transformer')\n",
    "# parser.add_argument('--batch_size', type=int, default=10)\n",
    "# parser.add_argument('--workers', type=int, default=0)\n",
    "# parser.add_argument('--features_path', type=str)\n",
    "# parser.add_argument('--annotation_folder', type=str)\n",
    "# args = parser.parse_args()\n",
    "batch_size = 1\n",
    "workers = 0\n",
    "features_path = \"../Dataset/coco/coco_detection.hdf5\"\n",
    "annotation_folder = \"../Dataset/coco/annotations/\"\n",
    "\n",
    "print('Meshed-Memory Transformer Evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31a88f0-291a-4cb3-a309-2f712b337a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pipeline: done !\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for text\n",
    "text_field = TextField(init_token='<bos>', eos_token='<eos>', lower=True, tokenize='spacy',\n",
    "                       remove_punctuation=True, nopoints=False)\n",
    "\n",
    "print(\"Creating pipeline: done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62c24f6-1046-4679-a3fc-8d6460ce2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset: done !\n"
     ]
    }
   ],
   "source": [
    "                  # paired dataset\n",
    "text_field.vocab = pickle.load(open('vocab.pkl', 'rb'))\n",
    "\n",
    "print(\"Creating dataset: done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658e7ef2-82ac-4210-8dc5-04f54d9c689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialise model: done !\n"
     ]
    }
   ],
   "source": [
    "# Model and dataloaders\n",
    "encoder = MemoryAugmentedEncoder(3, 0, attention_module=ScaledDotProductAttentionMemory,\n",
    "                                 attention_module_kwargs={'m': 40})\n",
    "decoder = MeshedDecoder(len(text_field.vocab), 54, 3, text_field.vocab.stoi['<pad>'])\n",
    "model = Transformer(text_field.vocab.stoi['<bos>'], encoder, decoder).to(device)\n",
    "\n",
    "print(\"Initialise model: done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc63a403-95fa-47e5-9341-cc1886593386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model parameters: done !\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('meshed_memory_transformer.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "\n",
    "print(\"Load model parameters: done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c23f9f-dd96-46c6-afa7-496f23068307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader: done !\n"
     ]
    }
   ],
   "source": [
    "dict_dataset_test = test_dataset.image_dictionary({'image': image_field, 'text': RawField()})          # dictionary dataset\n",
    "dict_dataloader_test = DataLoader(dict_dataset_test, batch_size=batch_size, num_workers=workers)\n",
    "\n",
    "print(\"Dataloader: done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bff8312-b677-4c5d-a7d7-b0ebc7f853c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratch model\n",
    "scores = predict_captions(model, dict_dataloader_test, text_field)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7e2fa-6dc6-4925-a36f-d6aa8be06372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06ba03fd-7c3e-4d65-be84-b1d02fe7edf1",
   "metadata": {},
   "source": [
    "### describe one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ea0c4d-283f-4705-b2a9-11466219fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import random\n",
    "from data import ImageDetectionsField, TextField, RawField\n",
    "from data import COCO, DataLoader\n",
    "import evaluation\n",
    "from models.transformer import Transformer, MemoryAugmentedEncoder, MeshedDecoder, ScaledDotProductAttentionMemory\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843edde4-2fc3-40e3-b973-013c37be4831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialise model: done !\n"
     ]
    }
   ],
   "source": [
    "text_field = TextField(init_token='<bos>', eos_token='<eos>', lower=True, tokenize='spacy',\n",
    "                       remove_punctuation=True, nopoints=False)\n",
    "text_field.vocab = pickle.load(open('vocab.pkl', 'rb'))\n",
    "\n",
    "encoder = MemoryAugmentedEncoder(3, 0, attention_module=ScaledDotProductAttentionMemory,\n",
    "                                 attention_module_kwargs={'m': 40})\n",
    "decoder = MeshedDecoder(len(text_field.vocab), 54, 3, text_field.vocab.stoi['<pad>'])\n",
    "\n",
    "model = Transformer(text_field.vocab.stoi['<bos>'], encoder, decoder).to(device)\n",
    "\n",
    "data = torch.load('saved_models/artpedia_finetune_singlecap.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "\n",
    "print(\"Initialise model: done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf52b4d5-f8f6-472f-a4b8-ada5dce905fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation by top-k sampling\n",
      "tensor([[  28, 2953,    0,    9,    4,    0,   12,   10,   23,    8,    4,    0,\n",
      "         2473,  756,   50,    0,    0,    0,    0,    3]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'it depicts <unk> with a <unk> man and woman in a <unk> oil painting by <unk> <unk> <unk> <unk>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose an image\n",
    "images = torch.tensor(np.load(\"../Dataset/artpedia/artpedia_features/100.npz\")['x']).to(device)\n",
    "images = images[:50].unsqueeze(dim=0)\n",
    "\n",
    "beam_size = 1\n",
    "out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], beam_size, out_size=1, is_sample=True)\n",
    "print(out)\n",
    "\" \".join(text_field.decode(out, join_words=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9fb027-3691-4240-abbe-ce291528bb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0979498-a147-48bb-8191-f2961266bddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1382f-16c2-45ad-bc6d-892b6a5fdbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca94a276-90dc-4335-ae06-99c686213d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------\n",
      "0.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[   7,  756, 2953,    7,    0,    6,    4,    0,    0,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "the painting depicts the <unk> of a <unk> <unk>\n",
      "\n",
      "------------\n",
      "1.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[  28, 2953,    7,  756,    6,    7,    0,    6,    7,    0,    6,    0,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "it depicts the painting of the <unk> of the <unk> of <unk>\n",
      "\n",
      "------------\n",
      "10.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[  28, 2953,    7,    0,    6,    7,  756,    6,    0, 3584,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0, 3505,   10]], device='cuda:0')\n",
      "it depicts the <unk> of the painting of <unk> ( <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> ) and\n",
      "\n",
      "------------\n",
      "100.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[   7,  756, 2953,    4,   51,   12,   10,   23,   14,   17,    4,   25,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "the painting depicts a young man and woman sitting at a table\n",
      "\n",
      "------------\n",
      "1000.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[   7,  756, 2953,   16,  191,  315,  449,  509,    0,   50,    4,    0,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "the painting depicts two women who have been <unk> by a <unk>\n",
      "\n",
      "------------\n",
      "1001.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[   7,  756, 2953,    7,    0,    6,    0, 3584,    0,    0,    0, 3505,\n",
      "           11,   15, 2473,  756,   50,    0,    0,    0]], device='cuda:0')\n",
      "the painting depicts the <unk> of <unk> ( <unk> <unk> <unk> ) is an oil painting by <unk> <unk> <unk>\n",
      "\n",
      "------------\n",
      "1002.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[  28, 2953,    4,   51,   23,   14,    5,    4,  164,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "it depicts a young woman sitting on a chair\n",
      "\n",
      "------------\n",
      "1003.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[   7,  756, 2953,   78,   19,   14,    5,    4,  173,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "the painting depicts three people sitting on a couch\n",
      "\n",
      "------------\n",
      "1004.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[   7,  756, 2953,    4,   51,   23,    8,    4,   22,  525,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "the painting depicts a young woman in a white dress\n",
      "\n",
      "------------\n",
      "1005.npz\n",
      "generation by beam search with beam size 5\n",
      "tensor([[   7,  756, 2953,    4,   34,    6,   19,    8,    4,   45,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "the painting depicts a group of people in a room\n"
     ]
    }
   ],
   "source": [
    "for file_name in os.listdir(\"../Dataset/artpedia/artpedia_features/\")[:10]:\n",
    "    print(\"\\n------------\")\n",
    "    print(file_name)\n",
    "    file_path = \"../Dataset/artpedia/artpedia_features/\" + file_name\n",
    "    images = torch.tensor(np.load(file_path)['x']).to(device)\n",
    "    images = images[:50].unsqueeze(dim=0)\n",
    "    with torch.no_grad():\n",
    "        out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 5, out_size=1)\n",
    "        print(out)\n",
    "        caps_gen = text_field.decode(out, join_words=False)\n",
    "        print(\" \".join(caps_gen[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bb9b30f-91f6-4b4e-85d0-8ea301448fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------\n",
      "0.npz\n",
      "generation by top-k sampling\n",
      "tensor([[   7,    0,   11,    0,   13,  338,   15, 2473,    5, 3848,  756,    0,\n",
      "            0,    8,    0,   10,    7,    0,    3,    0]], device='cuda:0')\n",
      "the <unk> is <unk> to be an oil on canvas painting <unk> <unk> in <unk> and the <unk>\n",
      "\n",
      "------------\n",
      "1.npz\n",
      "generation by top-k sampling\n",
      "tensor([[  28, 2953,    0, 3584, 3505,    0,    8,    0,    0,    0,    0, 3505,\n",
      "           11,    7,    0,  756,    7, 4485,    6,    7]], device='cuda:0')\n",
      "it depicts <unk> ( ) <unk> in <unk> <unk> <unk> <unk> ) is the <unk> painting the artist of the\n",
      "\n",
      "------------\n",
      "10.npz\n",
      "generation by top-k sampling\n",
      "tensor([[  28, 2953,   16,  191,  315,  449,    0,    0,    0, 3584,    0,    0,\n",
      "            0, 3505,  122,  575,  449,  509,    0,   50]], device='cuda:0')\n",
      "it depicts two women who have <unk> <unk> <unk> ( <unk> <unk> <unk> ) as they have been <unk> by\n",
      "\n",
      "------------\n",
      "100.npz\n",
      "generation by top-k sampling\n",
      "tensor([[  28,  550,    0,  129,    0,    0,    0,    0, 3584, 3505,   11,   15,\n",
      "         2473,  756,   50,    0,    0,    0,    3,    0]], device='cuda:0')\n",
      "it shows <unk> 's <unk> <unk> <unk> <unk> ( ) is an oil painting by <unk> <unk> <unk>\n",
      "\n",
      "------------\n",
      "1000.npz\n",
      "generation by top-k sampling\n",
      "tensor([[  28, 2953,   16,  191,    8,    4, 1074,    5, 3848,    7, 1888,    0,\n",
      "           13,    0,    7,    0,    8,    0,    0,    0]], device='cuda:0')\n",
      "it depicts two women in a costume on canvas the portrait <unk> to <unk> the <unk> in <unk> <unk> <unk>\n",
      "\n",
      "------------\n",
      "1001.npz\n",
      "generation by top-k sampling\n",
      "tensor([[   0,    8,    7,  915,    0, 3584,    0,    0,    0, 3505,   11,    0,\n",
      "            7,  756,    6,    7,    0,    8,    7,  756]], device='cuda:0')\n",
      "<unk> in the foreground <unk> ( <unk> <unk> <unk> ) is <unk> the painting of the <unk> in the painting\n",
      "\n",
      "------------\n",
      "1002.npz\n",
      "generation by top-k sampling\n",
      "tensor([[   7, 1888,    0,    4,   51,   12,   11,    4,  756,   50,    0,    0,\n",
      "            0,    0,    3,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "the portrait <unk> a young man is a painting by <unk> <unk> <unk> <unk>\n",
      "\n",
      "------------\n",
      "1003.npz\n",
      "generation by top-k sampling\n",
      "tensor([[   4,   12,    0,    4,   23,   11,   15,  142,   12,   10,    4,   96,\n",
      "            9,   90, 2031,    9,    4,  210,    5,    4]], device='cuda:0')\n",
      "a man <unk> a woman is an old man and a girl with her daughter with a baby on a\n",
      "\n",
      "------------\n",
      "1004.npz\n",
      "generation by top-k sampling\n",
      "tensor([[  28, 2953,    4,   96,  315,   11,    0,    0,    0,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0')\n",
      "it depicts a girl who is <unk> <unk> <unk>\n",
      "\n",
      "------------\n",
      "1005.npz\n",
      "generation by top-k sampling\n",
      "tensor([[   4,  756,    6,    0,    0, 3584,    7,    0,    0, 3505,   10,    0,\n",
      "         3505,   11,    4,  756,   50,    4,    0, 4485]], device='cuda:0')\n",
      "a painting of <unk> <unk> ( the <unk> <unk> ) and <unk> ) is a painting by a <unk> artist\n"
     ]
    }
   ],
   "source": [
    "for file_name in os.listdir(\"../Dataset/artpedia/artpedia_features/\")[:10]:\n",
    "    print(\"\\n------------\")\n",
    "    print(file_name)\n",
    "    file_path = \"../Dataset/artpedia/artpedia_features/\" + file_name\n",
    "    images = torch.tensor(np.load(file_path)['x']).to(device)\n",
    "    images = images[:50].unsqueeze(dim=0)\n",
    "    with torch.no_grad():\n",
    "        out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 1, out_size=1, is_sample=True)\n",
    "        print(out)\n",
    "        caps_gen = text_field.decode(out, join_words=False)\n",
    "        print(\" \".join(caps_gen[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c781f0-59c6-464f-b7f0-725863d0bb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f5dbd-7362-4736-a1bb-97e374c12f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99a25b2f-25fd-4424-9ac2-c98765fbf7af",
   "metadata": {},
   "source": [
    "top-k sampling will generate more unk token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca41295e-d7b1-405f-a49a-671e48374b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2release",
   "language": "python",
   "name": "m2release"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
