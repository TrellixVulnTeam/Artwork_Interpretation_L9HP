{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188733f4-567a-43ca-a309-8c23e3266769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from data import ImageDetectionsField, TextField, RawField\n",
    "from data import COCO, DataLoader\n",
    "from data.dataset import AP_Dataset, APeval_Dataset, SA_Dataset, SAeval_Dataset\n",
    "import evaluation\n",
    "from evaluation import PTBTokenizer, Cider\n",
    "# from models.transformer import Transformer, MemoryAugmentedEncoder, MeshedDecoder, ScaledDotProductAttentionMemory\n",
    "from models.grid_m2_rst import  Transformer, TransformerEncoder, MeshedDecoder, ScaledDotProductAttention\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.nn import NLLLoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import argparse, os, pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from shutil import copyfile\n",
    "import h5py\n",
    "from utils import text_progress2, text_progress\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65ee104-c363-473a-8c6c-56105168407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, dataloader, text_field, mode=\"multiple\", is_sample=False, beam_size=5, top_k=5, top_p=0.8):\n",
    "    import itertools\n",
    "    print(dataloader)\n",
    "    print(mode)\n",
    "    model.eval()\n",
    "    gen = {}\n",
    "    gts = {}\n",
    "    with tqdm(desc='evalulateion metrics', unit='it', total=len(dataloader)) as pbar:\n",
    "        for it, batch in enumerate(iter(dataloader)):\n",
    "            images = batch['roi_feat']\n",
    "            caps_gt = batch['cap']\n",
    "            images = images.to(device)\n",
    "            with torch.no_grad():\n",
    "#                 beam_size = 5\n",
    "                out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], beam_size, out_size=1, is_sample=is_sample, top_k=5, top_p=0.8)\n",
    "#                 if decode == \"beam_search\":\n",
    "#                     out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 5, out_size=1, is_sample=False)\n",
    "#                 elif decode == \"top-k_sampling\":\n",
    "#                     out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 1, out_size=1, is_sample=True)\n",
    "            caps_gen = text_field.decode(out, join_words=False)\n",
    "            for i, (gts_i, gen_i) in enumerate(zip(caps_gt, caps_gen)):\n",
    "                gen_i = ' '.join([k for k, g in itertools.groupby(gen_i)])\n",
    "                gen['%d_%d' % (it, i)] = [gen_i, ]\n",
    "                if mode == \"multiple\":\n",
    "                    gts['%d_%d' % (it, i)] = gts_i\n",
    "                elif mode == \"single\":\n",
    "                    gts['%d_%d' % (it, i)] = [gts_i[0]]\n",
    "            pbar.update()\n",
    "\n",
    "    gts = evaluation.PTBTokenizer.tokenize(gts)\n",
    "    gen = evaluation.PTBTokenizer.tokenize(gen)\n",
    "    scores, _ = evaluation.compute_scores(gts, gen, spice=False)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb3c8e-c055-4ac0-aa70-4a312b25b17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f0b12d-fa33-4443-9498-dbc3aee9d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2700e21-55c7-42ee-9268-75558e696a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "text_field = TextField(init_token='<bos>', eos_token='<eos>', lower=True, tokenize='spacy',\n",
    "                       remove_punctuation=True, nopoints=False)\n",
    "text_field.vocab = pickle.load(open('vocab.pkl', 'rb'))\n",
    "\n",
    "encoder = TransformerEncoder(3, 0, attention_module=ScaledDotProductAttention, attention_module_kwargs={'m': 40})\n",
    "decoder = MeshedDecoder(len(text_field.vocab), 54, 3, text_field.vocab.stoi['<pad>'])\n",
    "model = Transformer(text_field.vocab.stoi['<bos>'], encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6640d7-492b-4377-a09b-29e94979691a",
   "metadata": {},
   "source": [
    "## 1. artpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7cf6de3-3cfd-4dac-a1d6-d64ec41fdad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: done!!!\n"
     ]
    }
   ],
   "source": [
    "train_myidx = np.load('../Dataset/artpedia/train_myidx.npy')\n",
    "val_myidx = np.load('../Dataset/artpedia/val_myidx.npy')\n",
    "test_myidx = np.load('../Dataset/artpedia/test_myidx.npy')\n",
    "\n",
    "ap_train_dataset = h5py.File(\"../Dataset/artpedia/ap_train_grid.hdf5\", \"r\")\n",
    "ap_val_dataset = h5py.File(\"../Dataset/artpedia/ap_val_grid.hdf5\", \"r\")\n",
    "ap_test_dataset = h5py.File(\"../Dataset/artpedia/ap_test_grid.hdf5\", \"r\")\n",
    "print(\"loading data: done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "488f8c01-5e00-42d0-8a96-ee2380fac9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artpedia dataset\n",
    "dict_artpedia_test = APeval_Dataset(ap_test_dataset, test_myidx, text_field, max_detections=49, feature_type=\"grid\", lower=True, remove_punctuation=True, tokenize='spacy')\n",
    "\n",
    "# artpedia, dataloader\n",
    "dict_artpedia_test_data_loader = TorchDataLoader(dict_artpedia_test, batch_size=50, collate_fn=lambda x: text_progress2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1bc509-fce3-4517-aa44-d3e14147af94",
   "metadata": {},
   "source": [
    "#### 1.1 artpedia, one caption for evaluation, beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c7c6f-b02a-427e-ab1f-312a5ecaebea",
   "metadata": {},
   "source": [
    "#### 1.2 artpedia, multiple captions for evaluation, beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a8a17b-2cb3-4d78-a169-fc5b2cefd1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f819fdbdbe0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:09<00:00,  1.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.16722814874916128,\n",
       "  0.0647967385843378,\n",
       "  0.026314210811938347,\n",
       "  0.013047885850321551],\n",
       " 'METEOR': 0.04336997219011802,\n",
       " 'ROUGE': 0.1567383673086055,\n",
       " 'CIDEr': 0.020031510059636076}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** grid_m2rst\n",
    "# without fine-tuning, off-the-shelf model\n",
    "data = torch.load('saved_models_grid_m2rst/grid_m2_rst_best.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a86c41-9c3f-4ffb-9486-c246083b9556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f819fdbdbe0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:09<00:00,  1.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.16766664243617874,\n",
       "  0.06706854786854069,\n",
       "  0.02652070869867405,\n",
       "  0.013109732358008455],\n",
       " 'METEOR': 0.04340685159778225,\n",
       " 'ROUGE': 0.15892789987745576,\n",
       " 'CIDEr': 0.02003948688173837}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** grid_m2rst\n",
    "# without fine-tuning, off-the-shelf model\n",
    "data = torch.load('saved_models_grid_m2rst/grid_m2_rst_last.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe49209f-fa21-4513-9674-362f40300d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f819fdbdbe0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:09<00:00,  1.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.16552490383500296,\n",
       "  0.06339171836966011,\n",
       "  0.024411996142851448,\n",
       "  0.011465048096354524],\n",
       " 'METEOR': 0.04304402204721149,\n",
       " 'ROUGE': 0.15745674695633402,\n",
       " 'CIDEr': 0.019602907170169808}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** grid_m2rst\n",
    "# without fine-tuning, off-the-shelf model\n",
    "data = torch.load('saved_models_grid_m2rst/grid_m2_rst_epoch41.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed8a3825-0fd6-4bcc-be54-e7697234b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f1660140860>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.2263770796898909,\n",
       "  0.10189771635005827,\n",
       "  0.04723688221258288,\n",
       "  0.024825597404249923],\n",
       " 'ROUGE': 0.2044362212159059,\n",
       " 'CIDEr': 0.03947330064255181}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with one caption for training\n",
    "data = torch.load('saved_models/artpedia_finetune_singlecap.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9eb92-8f5b-475f-b55b-5f27f7443551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dcfa966-545c-4d34-932f-3f93451ec601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f819fdbdbe0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:09<00:00,  1.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.24697949865754792,\n",
       "  0.12218483456845088,\n",
       "  0.05717566420149227,\n",
       "  0.030616814624825857],\n",
       " 'METEOR': 0.06583208797468693,\n",
       " 'ROUGE': 0.22393089972424116,\n",
       " 'CIDEr': 0.039414558295047364}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** grid_m2rst\n",
    "# fine-tune on artpedia, one image with multiple captions for training\n",
    "data = torch.load('saved_models/grid_m2_tr_last_18epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1960b58e-52ca-4c41-92ab-0298ef20a7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f1660140860>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.21496088729295892,\n",
       "  0.10277365798269977,\n",
       "  0.04822575058710956,\n",
       "  0.024778542489085762],\n",
       " 'ROUGE': 0.2091605244824866,\n",
       " 'CIDEr': 0.03343695862148488}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9c7f89-3625-4677-a1f2-ae64d2a85ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fd22eadd0f0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:03<00:00,  5.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.23290164145038766,\n",
       "  0.11628312648636245,\n",
       "  0.052702077361140964,\n",
       "  0.02689678159915748],\n",
       " 'ROUGE': 0.21914811563939154,\n",
       " 'CIDEr': 0.03148247854508848}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfac020-93e3-4a39-8809-d88e635b088c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d42a19-ff8c-4647-bc54-d3e765365d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f49562804e0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:05<00:00,  5.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.33960716243253547,\n",
       "  0.16180978856929548,\n",
       "  0.0747107343165195,\n",
       "  0.035472046837868663],\n",
       " 'ROUGE': 0.22451221642237176,\n",
       " 'CIDEr': 0.06145132500410184}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beam search   remove unk\n",
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, is_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b4e44e-eef0-482c-aafb-55daa12bb25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f2055ff5588>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.3609881069135,\n",
       "  0.17902517899338843,\n",
       "  0.09118977721377369,\n",
       "  0.050181107544762536],\n",
       " 'METEOR': 0.09133971685517936,\n",
       " 'ROUGE': 0.23398104425547456,\n",
       " 'CIDEr': 0.09330209254997349}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beam search   remove unk\n",
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models_grid_m2rst_apft/grid_m2_tr_last_18epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, is_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bfe0e8-bbed-4c5e-8886-c19de592dc24",
   "metadata": {},
   "source": [
    "## 2. semart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63624600-04f8-419c-b8f0-10c6942c8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_test_csv = pd.read_csv(\"../Dataset/SemArt/prediction_csvs/semart_test_prediction.csv\")\n",
    "sa_test_csv = sa_test_csv[sa_test_csv['predictioin']==0]\n",
    "test_roi_feats = h5py.File(\"../Dataset/SemArt/sa_test_grid.hdf5\", \"r\")\n",
    "test_img_names = np.unique(sa_test_csv['img_name'].to_numpy())\n",
    "test_img_caps_map = json.load(open('../Dataset/SemArt/test_img_caps_map.json'))\n",
    "\n",
    "dict_semart_test = SAeval_Dataset(sa_test_csv, test_img_names, test_img_caps_map, test_roi_feats, text_field, max_detections=49, lower=True, remove_punctuation=True, tokenize='spacy')\n",
    "dict_semart_test_data_loader = TorchDataLoader(dict_semart_test, batch_size=50,\n",
    "                                  collate_fn=lambda x: text_progress2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89f439-5d51-4d68-906f-6333e189342e",
   "metadata": {},
   "source": [
    "#### 2.1 semart, multiple captions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92274535-f856-404d-a5ed-04165fc33bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f70735d40b8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:22<00:00,  1.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.1238723982265556,\n",
       "  0.04377896610833391,\n",
       "  0.017749577060783853,\n",
       "  0.008296285553807443],\n",
       " 'METEOR': 0.03853641775444528,\n",
       " 'ROUGE': 0.1403943502673313,\n",
       " 'CIDEr': 0.026411970140918662}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# off-the-shelf model\n",
    "data = torch.load('saved_models/saved_models_grid_m2rst/grid_m2_rst_last.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05f475c-96fa-4e9a-80a7-6651b6f09b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f70735d40b8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:22<00:00,  1.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.12809294283327557,\n",
       "  0.045397722109473716,\n",
       "  0.01791234797525151,\n",
       "  0.007650384719347912],\n",
       " 'METEOR': 0.039360563038510016,\n",
       " 'ROUGE': 0.142495980976305,\n",
       " 'CIDEr': 0.020916017474374143}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# off-the-shelf model\n",
    "data = torch.load('saved_models/saved_models_grid_m2rst/grid_m2_rst_best.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae06fdd2-5acf-4d8a-8c2d-16f1a103275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f70735d40b8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:22<00:00,  1.70s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.13904005551409623,\n",
       "  0.04929343466036093,\n",
       "  0.019266916799502324,\n",
       "  0.008159874882971943],\n",
       " 'METEOR': 0.03898631586267387,\n",
       " 'ROUGE': 0.13827194208741386,\n",
       " 'CIDEr': 0.02001249028494681}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# off-the-shelf model\n",
    "data = torch.load('saved_models/saved_models_grid_m2rst/grid_m2_rst_epoch41.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd055763-d596-466d-b2c3-100dbae7681a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc78ceb3-4224-4fb2-ab10-ab7d91d0200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f9980ae1e80>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.1793097313567625,\n",
       "  0.08845628213335589,\n",
       "  0.04550863303247926,\n",
       "  0.027544256454569226],\n",
       " 'METEOR': 0.059977900521655046,\n",
       " 'ROUGE': 0.210684243568821,\n",
       " 'CIDEr': 0.05792592281250193}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt    remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2rst/sa_gridm2rst_sa_last_17epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d100c4c-a934-4eb4-a6cf-b6647291a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f9980ae1e80>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:17<00:00,  1.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.19366517108620626,\n",
       "  0.09414067272111563,\n",
       "  0.047131246404860994,\n",
       "  0.02727318372337316],\n",
       " 'METEOR': 0.06290828571071426,\n",
       " 'ROUGE': 0.21849475404941598,\n",
       " 'CIDEr': 0.0640887464734465}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt          remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2rst/sa_gridm2rst_sa_best_13epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dec64d9-cf7d-4b69-91ee-a5160acb3fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f9980ae1e80>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:17<00:00,  1.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.20122972946628226,\n",
       "  0.10130244427949057,\n",
       "  0.05035051252524529,\n",
       "  0.029524666351640177],\n",
       " 'METEOR': 0.06385577952828095,\n",
       " 'ROUGE': 0.21882635632016711,\n",
       " 'CIDEr': 0.07495384156844488}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt             remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2rst/sa_gridm2rst_sa_last_15epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10cbf05-226b-4355-ab14-e79e760ee4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f9980ae1e80>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:17<00:00,  1.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.19248471632586958,\n",
       "  0.09910268608348924,\n",
       "  0.0526078570669242,\n",
       "  0.03235305832917967],\n",
       " 'METEOR': 0.06283993741113443,\n",
       " 'ROUGE': 0.2192800786090442,\n",
       " 'CIDEr': 0.0693193711305087}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt            remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2rst/sa_gridm2rst_sa_last_16epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b1b83-7245-485e-b7a9-dbfe7559c33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfefa08-88e2-4c35-a542-ac20b1436274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0882d6-f4e2-4fda-8ab0-5d22dfe7f639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac3d9dd-b0c1-4986-a942-f9e7cd2c0500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f70735d40b8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:22<00:00,  1.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.3072302366961828,\n",
       "  0.15600789631516362,\n",
       "  0.07752334709721519,\n",
       "  0.04534257500040296],\n",
       " 'METEOR': 0.08315250711965914,\n",
       " 'ROUGE': 0.23498774340842055,\n",
       " 'CIDEr': 0.09807077016422536}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt    remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2rst/sa_gridm2rst_sa_last_17epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a63f876-4bc2-45ed-af4c-c8bbd34b3f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f70735d40b8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:22<00:00,  1.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.31320652324860604,\n",
       "  0.15754597536164425,\n",
       "  0.0777770804175481,\n",
       "  0.04421370018307126],\n",
       " 'METEOR': 0.08476561809644537,\n",
       " 'ROUGE': 0.23779380640853018,\n",
       " 'CIDEr': 0.09827848953660719}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt          remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2rst/sa_gridm2rst_sa_best_13epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14495fc8-d4ad-4886-9c33-7722a9886039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f70735d40b8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:22<00:00,  1.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.31100768669817086,\n",
       "  0.1571050036064454,\n",
       "  0.07634610949345182,\n",
       "  0.04242987274654262],\n",
       " 'METEOR': 0.08418395341362825,\n",
       " 'ROUGE': 0.23695722537609906,\n",
       " 'CIDEr': 0.09888653207449181}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt             remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2rst/sa_gridm2rst_sa_last_15epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0015e8ea-b1c5-4d4f-b7f7-b7a39a0eb809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f70735d40b8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 13/13 [00:22<00:00,  1.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.3125313141354439,\n",
       "  0.15712767945367956,\n",
       "  0.076700577593618,\n",
       "  0.043780874821767166],\n",
       " 'METEOR': 0.0846857648929584,\n",
       " 'ROUGE': 0.23493355890015902,\n",
       " 'CIDEr': 0.09656533432493654}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt            remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2rst/sa_gridm2rst_sa_last_16epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e5605-c1f5-42b0-9344-70f48e9d062b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8abf39-ea06-4978-8fd3-1bc15093fb39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefa491-283b-4256-b0e7-99fef3db4521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db073bb-04fa-41fd-b609-3172ed25941f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2release",
   "language": "python",
   "name": "m2release"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
