{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188733f4-567a-43ca-a309-8c23e3266769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from data import ImageDetectionsField, TextField, RawField\n",
    "from data import COCO, DataLoader\n",
    "from data.dataset import AP_Dataset, APeval_Dataset, SA_Dataset, SAeval_Dataset\n",
    "import evaluation\n",
    "from evaluation import PTBTokenizer, Cider\n",
    "# from models.transformer import Transformer, MemoryAugmentedEncoder, MeshedDecoder, ScaledDotProductAttentionMemory\n",
    "from models.grid_m2 import Transformer, TransformerEncoder, MeshedDecoder, ScaledDotProductAttentionMemory, ScaledDotProductAttention\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.nn import NLLLoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import argparse, os, pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from shutil import copyfile\n",
    "import h5py\n",
    "from utils import text_progress2, text_progress\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65ee104-c363-473a-8c6c-56105168407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, dataloader, text_field, mode=\"multiple\", is_sample=False, beam_size=5, top_k=5, top_p=0.8):\n",
    "    import itertools\n",
    "    print(dataloader)\n",
    "    print(mode)\n",
    "    model.eval()\n",
    "    gen = {}\n",
    "    gts = {}\n",
    "    with tqdm(desc='evalulateion metrics', unit='it', total=len(dataloader)) as pbar:\n",
    "        for it, batch in enumerate(iter(dataloader)):\n",
    "            images = batch['roi_feat']\n",
    "            caps_gt = batch['cap']\n",
    "            images = images.to(device)\n",
    "            with torch.no_grad():\n",
    "#                 beam_size = 5\n",
    "                out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], beam_size, out_size=1, is_sample=is_sample, top_k=5, top_p=0.8)\n",
    "#                 if decode == \"beam_search\":\n",
    "#                     out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 5, out_size=1, is_sample=False)\n",
    "#                 elif decode == \"top-k_sampling\":\n",
    "#                     out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 1, out_size=1, is_sample=True)\n",
    "            caps_gen = text_field.decode(out, join_words=False)\n",
    "            for i, (gts_i, gen_i) in enumerate(zip(caps_gt, caps_gen)):\n",
    "                gen_i = ' '.join([k for k, g in itertools.groupby(gen_i)])\n",
    "                gen['%d_%d' % (it, i)] = [gen_i, ]\n",
    "                if mode == \"multiple\":\n",
    "                    gts['%d_%d' % (it, i)] = gts_i\n",
    "                elif mode == \"single\":\n",
    "                    gts['%d_%d' % (it, i)] = [gts_i[0]]\n",
    "            pbar.update()\n",
    "\n",
    "    gts = evaluation.PTBTokenizer.tokenize(gts)\n",
    "    gen = evaluation.PTBTokenizer.tokenize(gen)\n",
    "    scores, _ = evaluation.compute_scores(gts, gen, spice=False)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb3c8e-c055-4ac0-aa70-4a312b25b17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f0b12d-fa33-4443-9498-dbc3aee9d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2700e21-55c7-42ee-9268-75558e696a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "text_field = TextField(init_token='<bos>', eos_token='<eos>', lower=True, tokenize='spacy',\n",
    "                       remove_punctuation=True, nopoints=False)\n",
    "text_field.vocab = pickle.load(open('vocab.pkl', 'rb'))\n",
    "\n",
    "encoder = TransformerEncoder(3, 0, attention_module=ScaledDotProductAttention, attention_module_kwargs={'m': 40})\n",
    "decoder = MeshedDecoder(len(text_field.vocab), 54, 3, text_field.vocab.stoi['<pad>'])\n",
    "model = Transformer(text_field.vocab.stoi['<bos>'], encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6640d7-492b-4377-a09b-29e94979691a",
   "metadata": {},
   "source": [
    "## 1. artpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cf6de3-3cfd-4dac-a1d6-d64ec41fdad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: done!!!\n"
     ]
    }
   ],
   "source": [
    "train_myidx = np.load('../Dataset/artpedia/train_myidx.npy')\n",
    "val_myidx = np.load('../Dataset/artpedia/val_myidx.npy')\n",
    "test_myidx = np.load('../Dataset/artpedia/test_myidx.npy')\n",
    "\n",
    "ap_train_dataset = h5py.File(\"../Dataset/artpedia/ap_train_grid.hdf5\", \"r\")\n",
    "ap_val_dataset = h5py.File(\"../Dataset/artpedia/ap_val_grid.hdf5\", \"r\")\n",
    "ap_test_dataset = h5py.File(\"../Dataset/artpedia/ap_test_grid.hdf5\", \"r\")\n",
    "print(\"loading data: done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "488f8c01-5e00-42d0-8a96-ee2380fac9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artpedia dataset\n",
    "dict_artpedia_test = APeval_Dataset(ap_test_dataset, test_myidx, text_field, max_detections=49, lower=True, remove_punctuation=True, tokenize='spacy')\n",
    "\n",
    "# artpedia, dataloader\n",
    "dict_artpedia_test_data_loader = TorchDataLoader(dict_artpedia_test, batch_size=50, collate_fn=lambda x: text_progress2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1bc509-fce3-4517-aa44-d3e14147af94",
   "metadata": {},
   "source": [
    "#### 1.1 artpedia, one caption for evaluation, beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e75c5b3-306a-4b61-bc43-a250dcba5de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f1660140860>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.0001236055972225921,\n",
       "  4.035351405369087e-12,\n",
       "  1.3192351808657412e-14,\n",
       "  7.681117691112694e-16],\n",
       " 'ROUGE': 0.00017328068630514444,\n",
       " 'CIDEr': 2.058933461283359e-06}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scratch model\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode = \"single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992b45e1-bfea-4aca-956c-eebf95ccdea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f1660140860>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.06869365934607014,\n",
       "  0.02408617516886492,\n",
       "  0.009203178196801148,\n",
       "  0.004077820732889246],\n",
       " 'ROUGE': 0.1265856198220996,\n",
       " 'CIDEr': 0.035073845779796387}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without fine-tuning, off-the-shelf model\n",
    "data = torch.load('meshed_memory_transformer.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea105a5e-62bd-464d-be30-1c4c119a600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7faf5db3dcc0>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.10770007890173203,\n",
       "  0.042905798133398614,\n",
       "  0.021158617232954074,\n",
       "  0.011994791859808066],\n",
       " 'ROUGE': 0.16777807810792697,\n",
       " 'CIDEr': 0.05152375363409006}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with one caption for training\n",
    "data = torch.load('saved_models/artpedia_finetune_singlecap.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81142695-0557-4842-b6cd-e2a4a15bb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7faf5db3dcc0>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.10001649470859435,\n",
       "  0.04153007097875002,\n",
       "  0.020453615889150106,\n",
       "  0.010804099773927376],\n",
       " 'ROUGE': 0.16959301187547615,\n",
       " 'CIDEr': 0.04574429996778054}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a82b9e6-8f61-450e-92e0-f32af0a82cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7faf5db3dcc0>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.11439772302455756,\n",
       "  0.049840209225196434,\n",
       "  0.023219958693446556,\n",
       "  0.012087941730175456],\n",
       " 'ROUGE': 0.17763442833720808,\n",
       " 'CIDEr': 0.04937305896140482}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training   + shuffle\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee71940-0004-4a80-a145-46fb20ac0fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f49562804e0>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:05<00:00,  5.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.20352391671520823,\n",
       "  0.08086088054241472,\n",
       "  0.03645516117706604,\n",
       "  0.017655400779776953],\n",
       " 'ROUGE': 0.18542789079533953,\n",
       " 'CIDEr': 0.07592433158198265}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beam search.   remove <unk> token\n",
    "# fine-tune on artpedia, one image with multiple captions for training   + shuffle\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf010ed9-db61-4456-a878-f7f005e043cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504081d-3a13-44de-bc1d-e09fbf6c52ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00fc052f-94d8-447c-afca-c58129550c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fd22eadd0f0>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:00<00:00,  5.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.09333995593432404,\n",
       "  0.038172705149673934,\n",
       "  0.01817147245345931,\n",
       "  0.009833963777214086],\n",
       " 'ROUGE': 0.16580195687810742,\n",
       " 'CIDEr': 0.038267756192650784}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training   + shuffle\n",
    "# generation by top-k sampling    k=5\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='single', is_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb308f-5489-45e8-850d-8749a9394e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf5f1b8-d0c1-4ade-905a-51010c454f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f70e047ff28>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:02<00:00,  5.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.13215944908390478,\n",
       "  0.04599203906981929,\n",
       "  0.015877252152370982,\n",
       "  0.005857381895548809],\n",
       " 'ROUGE': 0.1465819237593196,\n",
       " 'CIDEr': 0.030852426204639675}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training   + shuffle\n",
    "# generation by top-k sampling    k=10\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='single', decode=\"top-k_sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "150315d5-7205-4f09-9330-f1ff42f9a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fd22eadd0f0>\n",
      "single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:02<00:00,  5.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.1336230293647883,\n",
       "  0.0478548036942355,\n",
       "  0.015488464819317658,\n",
       "  0.005749882420519693],\n",
       " 'ROUGE': 0.1460779368214854,\n",
       " 'CIDEr': 0.027999531132453754}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training   + shuffle\n",
    "# generation by top-k sampling    k=10\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='single', is_sample=True, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c7c6f-b02a-427e-ab1f-312a5ecaebea",
   "metadata": {},
   "source": [
    "#### 1.2 artpedia, multiple captions for evaluation, beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5a8a17b-2cb3-4d78-a169-fc5b2cefd1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5cbe8c7dd8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.16577379519943217,\n",
       "  0.06644457162762864,\n",
       "  0.026349137847583266,\n",
       "  0.011600651194181912],\n",
       " 'METEOR': 0.0433855656764746,\n",
       " 'ROUGE': 0.15793254273513543,\n",
       " 'CIDEr': 0.023743332859778445}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** grid_m2\n",
    "# without fine-tuning, off-the-shelf model\n",
    "data = torch.load('saved_models_grid_m2/grid_m2_best.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed8a3825-0fd6-4bcc-be54-e7697234b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f1660140860>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.2263770796898909,\n",
       "  0.10189771635005827,\n",
       "  0.04723688221258288,\n",
       "  0.024825597404249923],\n",
       " 'ROUGE': 0.2044362212159059,\n",
       " 'CIDEr': 0.03947330064255181}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with one caption for training\n",
    "data = torch.load('saved_models/artpedia_finetune_singlecap.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9eb92-8f5b-475f-b55b-5f27f7443551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dcfa966-545c-4d34-932f-3f93451ec601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f5cbe8c7dd8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.25296084904797095,\n",
       "  0.12311204765152903,\n",
       "  0.052697501977052766,\n",
       "  0.025706299968640323],\n",
       " 'METEOR': 0.06338670711351466,\n",
       " 'ROUGE': 0.2252853501235557,\n",
       " 'CIDEr': 0.03524534922558475}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** grid_m2\n",
    "# fine-tune on artpedia, one image with multiple captions for training\n",
    "data = torch.load('saved_models/grid_m2_tr_last_15epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1960b58e-52ca-4c41-92ab-0298ef20a7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f1660140860>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 66/66 [00:13<00:00,  4.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.21496088729295892,\n",
       "  0.10277365798269977,\n",
       "  0.04822575058710956,\n",
       "  0.024778542489085762],\n",
       " 'ROUGE': 0.2091605244824866,\n",
       " 'CIDEr': 0.03343695862148488}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9c7f89-3625-4677-a1f2-ae64d2a85ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fd22eadd0f0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:03<00:00,  5.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.23290164145038766,\n",
       "  0.11628312648636245,\n",
       "  0.052702077361140964,\n",
       "  0.02689678159915748],\n",
       " 'ROUGE': 0.21914811563939154,\n",
       " 'CIDEr': 0.03148247854508848}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfac020-93e3-4a39-8809-d88e635b088c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d42a19-ff8c-4647-bc54-d3e765365d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f49562804e0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:05<00:00,  5.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.33960716243253547,\n",
       "  0.16180978856929548,\n",
       "  0.0747107343165195,\n",
       "  0.035472046837868663],\n",
       " 'ROUGE': 0.22451221642237176,\n",
       " 'CIDEr': 0.06145132500410184}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beam search   remove unk\n",
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, is_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6319a989-ab7c-4fbb-91f3-12cc5df26a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f44b7dd60b8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:08<00:00,  1.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.35762850093836457,\n",
       "  0.17222325774134367,\n",
       "  0.08031597949946138,\n",
       "  0.0389859827653499],\n",
       " 'METEOR': 0.08842069618105143,\n",
       " 'ROUGE': 0.23075065821853866,\n",
       " 'CIDEr': 0.06807426873269039}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** grid_m2\n",
    "# beam search   remove unk\n",
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models/grid_m2_tr_last_15epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, is_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bfe0e8-bbed-4c5e-8886-c19de592dc24",
   "metadata": {},
   "source": [
    "## 2. semart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e796e9b-2e29-4f0b-9987-4b5cdbf7cfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63624600-04f8-419c-b8f0-10c6942c8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_test_csv = pd.read_csv(\"../Dataset/SemArt/prediction_csvs/semart_test_prediction.csv\")\n",
    "sa_test_csv = sa_test_csv[sa_test_csv['predictioin']==0]\n",
    "test_roi_feats = h5py.File(\"../Dataset/SemArt/sa_test_grid.hdf5\", \"r\")\n",
    "test_img_names = np.unique(sa_test_csv['img_name'].to_numpy())\n",
    "test_img_caps_map = json.load(open('../Dataset/SemArt/test_img_caps_map.json'))\n",
    "\n",
    "dict_semart_test = SAeval_Dataset(sa_test_csv, test_img_names, test_img_caps_map, test_roi_feats, text_field, max_detections=49, lower=True, remove_punctuation=True, tokenize='spacy')\n",
    "dict_semart_test_data_loader = TorchDataLoader(dict_semart_test, batch_size=10,\n",
    "                                  collate_fn=lambda x: text_progress2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89f439-5d51-4d68-906f-6333e189342e",
   "metadata": {},
   "source": [
    "#### 2.1 semart, multiple captions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92274535-f856-404d-a5ed-04165fc33bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f0b088faf60>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:15<00:00,  3.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.11533953842197162,\n",
       "  0.039782848723446396,\n",
       "  0.014352327712648954,\n",
       "  0.005583332053985084],\n",
       " 'METEOR': 0.037317946222108496,\n",
       " 'ROUGE': 0.1407143406791696,\n",
       " 'CIDEr': 0.020143350427409674}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# off-the-shelf model  ***\n",
    "data = torch.load('saved_models/saved_models_grid_m2/grid_m2_best.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b17a10-ed6f-425b-8ec9-29be384498e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac3d9dd-b0c1-4986-a942-f9e7cd2c0500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f0b088faf60>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:21<00:00,  2.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.21463416441072608,\n",
       "  0.1058966925124788,\n",
       "  0.05256788929370499,\n",
       "  0.030818367459357468],\n",
       " 'METEOR': 0.06387810691304108,\n",
       " 'ROUGE': 0.21598327906765846,\n",
       " 'CIDEr': 0.0599095238125901}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2/sa_gridm2_sa_last_10epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2d150c2-0d6a-466e-aa4b-1703e753eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f0b088faf60>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:15<00:00,  3.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.19316501521892346,\n",
       "  0.09220240830526882,\n",
       "  0.04682501367553965,\n",
       "  0.028436043589034024],\n",
       " 'METEOR': 0.06169974966082502,\n",
       " 'ROUGE': 0.2065315798846974,\n",
       " 'CIDEr': 0.06704352388762456}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2/sa_gridm2_sa_last_13epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c4d24df-31a0-4796-a8a0-cc56407d192a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fddc51a7e10>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:20<00:00,  2.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.31310133603043044,\n",
       "  0.153552917771243,\n",
       "  0.07456135060987139,\n",
       "  0.042422365680723065],\n",
       " 'METEOR': 0.08446232128562489,\n",
       " 'ROUGE': 0.23355387825854562,\n",
       " 'CIDEr': 0.10082804867346877}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2/sa_gridm2_sa_last_12epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e90b6035-2b9e-4e08-8100-5c4548725ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f0b088faf60>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:15<00:00,  3.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.19546150334262233,\n",
       "  0.09774340995591328,\n",
       "  0.051427166367178916,\n",
       "  0.03158941865261445],\n",
       " 'METEOR': 0.06383502717845177,\n",
       " 'ROUGE': 0.2160521035677449,\n",
       " 'CIDEr': 0.07208048787412573}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2/sa_gridm2_sa_last_11epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22135f23-4e76-4463-9fbb-090d1495fc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8f2c9-708c-41a5-8d14-378c01877a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d53db9-c8b3-438e-b74c-7a48761df13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fddc51a7e10>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:20<00:00,  2.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.3136397727171599,\n",
       "  0.1539397732792538,\n",
       "  0.07414077612473546,\n",
       "  0.04129592891984856],\n",
       " 'METEOR': 0.08531230505769902,\n",
       " 'ROUGE': 0.23569184859501466,\n",
       " 'CIDEr': 0.09515643902965266}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt     remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2/sa_gridm2_sa_last_11epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd6a7c8-5117-42d8-b193-893afb6e7e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fddc51a7e10>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:20<00:00,  3.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.3112334920154185,\n",
       "  0.15523951377741668,\n",
       "  0.07910016576933099,\n",
       "  0.04503895024022269],\n",
       " 'METEOR': 0.08413479323419014,\n",
       " 'ROUGE': 0.23497037598933013,\n",
       " 'CIDEr': 0.0950346285443715}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt     remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2/sa_gridm2_sa_last_10epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad690e9f-111e-4a90-a392-b09fb0e461d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fddc51a7e10>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:20<00:00,  3.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.31310133603043044,\n",
       "  0.153552917771243,\n",
       "  0.07456135060987139,\n",
       "  0.042422365680723065],\n",
       " 'METEOR': 0.08446232128562489,\n",
       " 'ROUGE': 0.23355387825854562,\n",
       " 'CIDEr': 0.10082804867346877}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt     remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2/sa_gridm2_sa_last_12epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f825bd89-cf2c-4d04-b8d9-278b7ca50e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fddc51a7e10>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:20<00:00,  3.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.3017095870446208,\n",
       "  0.1441650904246923,\n",
       "  0.07032731256466737,\n",
       "  0.039046321719393526],\n",
       " 'METEOR': 0.08222837145922787,\n",
       " 'ROUGE': 0.22438646854582237,\n",
       " 'CIDEr': 0.0967136906762575}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt     remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_grid_m2/sa_gridm2_sa_last_13epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88414d-b496-4ba9-b7b6-1221a71f956f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2release",
   "language": "python",
   "name": "m2release"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
