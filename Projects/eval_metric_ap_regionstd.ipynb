{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188733f4-567a-43ca-a309-8c23e3266769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/miniconda3/envs/m2release/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from data import ImageDetectionsField, TextField, RawField\n",
    "from data import COCO, DataLoader\n",
    "from data.dataset import AP_Dataset, APeval_Dataset, SA_Dataset, SAeval_Dataset\n",
    "import evaluation\n",
    "from evaluation import PTBTokenizer, Cider\n",
    "from models.transformer import Transformer, TransformerEncoder, TransformerDecoderLayer, ScaledDotProductAttentionMemory, ScaledDotProductAttention\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.nn import NLLLoss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import argparse, os, pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from shutil import copyfile\n",
    "import h5py\n",
    "from utils import text_progress2, text_progress\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65ee104-c363-473a-8c6c-56105168407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, dataloader, text_field, mode=\"multiple\", is_sample=False, beam_size=5, top_k=5, top_p=0.8):\n",
    "    import itertools\n",
    "    print(dataloader)\n",
    "    print(mode)\n",
    "    model.eval()\n",
    "    gen = {}\n",
    "    gts = {}\n",
    "    with tqdm(desc='evalulateion metrics', unit='it', total=len(dataloader)) as pbar:\n",
    "        for it, batch in enumerate(iter(dataloader)):\n",
    "            images = batch['roi_feat']\n",
    "            caps_gt = batch['cap']\n",
    "            images = images.to(device)\n",
    "            with torch.no_grad():\n",
    "#                 beam_size = 5\n",
    "                out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], beam_size, out_size=1, is_sample=is_sample, top_k=5, top_p=0.8)\n",
    "#                 if decode == \"beam_search\":\n",
    "#                     out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 5, out_size=1, is_sample=False)\n",
    "#                 elif decode == \"top-k_sampling\":\n",
    "#                     out, _ = model.beam_search(images, 20, text_field.vocab.stoi['<eos>'], 1, out_size=1, is_sample=True)\n",
    "            caps_gen = text_field.decode(out, join_words=False)\n",
    "            for i, (gts_i, gen_i) in enumerate(zip(caps_gt, caps_gen)):\n",
    "                gen_i = ' '.join([k for k, g in itertools.groupby(gen_i)])\n",
    "                gen['%d_%d' % (it, i)] = [gen_i, ]\n",
    "                if mode == \"multiple\":\n",
    "                    gts['%d_%d' % (it, i)] = gts_i\n",
    "                elif mode == \"single\":\n",
    "                    gts['%d_%d' % (it, i)] = [gts_i[0]]\n",
    "            pbar.update()\n",
    "\n",
    "    gts = evaluation.PTBTokenizer.tokenize(gts)\n",
    "    gen = evaluation.PTBTokenizer.tokenize(gen)\n",
    "    scores, _ = evaluation.compute_scores(gts, gen, spice=False)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb3c8e-c055-4ac0-aa70-4a312b25b17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f0b12d-fa33-4443-9498-dbc3aee9d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2700e21-55c7-42ee-9268-75558e696a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "text_field = TextField(init_token='<bos>', eos_token='<eos>', lower=True, tokenize='spacy',\n",
    "                       remove_punctuation=True, nopoints=False)\n",
    "text_field.vocab = pickle.load(open('vocab.pkl', 'rb'))\n",
    "\n",
    "encoder = TransformerEncoder(3, 0, attention_module=ScaledDotProductAttention, attention_module_kwargs={'m': 40})\n",
    "decoder = TransformerDecoderLayer(len(text_field.vocab), 54, 3, text_field.vocab.stoi['<pad>'])\n",
    "model = Transformer(text_field.vocab.stoi['<bos>'], encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6640d7-492b-4377-a09b-29e94979691a",
   "metadata": {},
   "source": [
    "## 1. artpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7cf6de3-3cfd-4dac-a1d6-d64ec41fdad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data: done!!!\n"
     ]
    }
   ],
   "source": [
    "train_myidx = np.load('../Dataset/artpedia/train_myidx.npy')\n",
    "val_myidx = np.load('../Dataset/artpedia/val_myidx.npy')\n",
    "test_myidx = np.load('../Dataset/artpedia/test_myidx.npy')\n",
    "\n",
    "ap_train_dataset = h5py.File(\"../Dataset/artpedia/ap_train_region.hdf5\", \"r\")\n",
    "ap_val_dataset = h5py.File(\"../Dataset/artpedia/ap_val_region.hdf5\", \"r\")\n",
    "ap_test_dataset = h5py.File(\"../Dataset/artpedia/ap_test_region.hdf5\", \"r\")\n",
    "print(\"loading data: done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488f8c01-5e00-42d0-8a96-ee2380fac9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artpedia dataset\n",
    "dict_artpedia_test = APeval_Dataset(ap_test_dataset, test_myidx, text_field, max_detections=50, feature_type=\"detector\", lower=True, remove_punctuation=True, tokenize='spacy')\n",
    "\n",
    "# artpedia, dataloader\n",
    "dict_artpedia_test_data_loader = TorchDataLoader(dict_artpedia_test, batch_size=50, collate_fn=lambda x: text_progress2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c7c6f-b02a-427e-ab1f-312a5ecaebea",
   "metadata": {},
   "source": [
    "#### 1.2 artpedia, multiple captions for evaluation, beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618c0638-5019-429e-aa75-2102b9bd9272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff2d81fafd0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:04<00:00,  1.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.00524318430199016,\n",
       "  2.836729807696152e-11,\n",
       "  5.072564320885483e-14,\n",
       "  2.1766323754403583e-15],\n",
       " 'METEOR': 0.015595644337142557,\n",
       " 'ROUGE': 0.004175462859047491,\n",
       " 'CIDEr': 0.0009228591392197886}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** region stdtr\n",
    "# scratch model\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0366b1-0120-4415-8f3c-e98d423403e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff2d81fafd0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:02<00:00,  2.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.15064964497653152,\n",
       "  0.05254520054357977,\n",
       "  0.012394490245029106,\n",
       "  7.835026833744943e-07],\n",
       " 'METEOR': 0.034218845998585906,\n",
       " 'ROUGE': 0.1514563893431952,\n",
       " 'CIDEr': 0.007221904742579137}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *** region stdtr\n",
    "# without fine-tuning, off-the-shelf model\n",
    "data = torch.load('saved_models_region_std/region_std_best.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ddd1771-99e5-4748-a929-98403465aee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff2d81fafd0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:02<00:00,  2.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.257237276372721,\n",
       "  0.1211514887443507,\n",
       "  0.05465593843534876,\n",
       "  0.0254420322759611],\n",
       " 'METEOR': 0.06266429495902702,\n",
       " 'ROUGE': 0.21395755142357425,\n",
       " 'CIDEr': 0.02933599737380237}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ** std transformer\n",
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models_region_std_apft/region_std_apft_last_17epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9b5f56f-2626-4bcf-822b-a615122090b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f3fe39d1e48>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:07<00:00,  1.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.33371795247170943,\n",
       "  0.15761846241713176,\n",
       "  0.07185717110044607,\n",
       "  0.03310101342775185],\n",
       " 'METEOR': 0.08320607069392956,\n",
       " 'ROUGE': 0.22028913774749376,\n",
       " 'CIDEr': 0.057944515408255085}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ** std transformer\n",
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models_region_std_apft/region_std_apft_last_17epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a1a0ccc-338f-494d-9798-7fd071272fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "../Dataset/artpedia/artpedia_region_features/1420\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../Dataset/artpedia/artpedia_region_features/1420.npz\"\n",
    "img = np.load(file_path)\n",
    "print(\"--------------\")\n",
    "print(file_path[:-4])\n",
    "#     img = processor(torch.tensor(img)).unsqueeze(0)\n",
    "img = torch.tensor([img['x']]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1437e42d-80b2-4c2a-bfc9-3cbfd49646b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, _ = model.beam_search(img, 20, text_field.vocab.stoi['<eos>'], 1, out_size=1, is_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ca41673-16c6-4669-9876-b473c863f554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it shows a nude woman with a large mirror'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_gen = text_field.decode(out, join_words=False)[0]\n",
    "caps_gen = ' '.join([k for k, g in itertools.groupby(caps_gen)])\n",
    "caps_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81d460-7638-4809-93ed-0096ae46165e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2075844-8c73-431f-9fcf-956f0a771dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7ff2d81fafd0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 7/7 [00:02<00:00,  2.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.25325047864758254,\n",
       "  0.1174482210374481,\n",
       "  0.051749822530998496,\n",
       "  0.02653207663796888],\n",
       " 'METEOR': 0.06306414530109579,\n",
       " 'ROUGE': 0.2156961450358094,\n",
       " 'CIDEr': 0.037402463240044696}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 太好了，隐藏\n",
    "# ** std transformer\n",
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models_region_std_apft/region_std_apft_last_21epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9c7f89-3625-4677-a1f2-ae64d2a85ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fd22eadd0f0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:03<00:00,  5.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.23290164145038766,\n",
       "  0.11628312648636245,\n",
       "  0.052702077361140964,\n",
       "  0.02689678159915748],\n",
       " 'ROUGE': 0.21914811563939154,\n",
       " 'CIDEr': 0.03148247854508848}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfac020-93e3-4a39-8809-d88e635b088c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d42a19-ff8c-4647-bc54-d3e765365d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f49562804e0>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 329/329 [01:05<00:00,  5.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.33960716243253547,\n",
       "  0.16180978856929548,\n",
       "  0.0747107343165195,\n",
       "  0.035472046837868663],\n",
       " 'ROUGE': 0.22451221642237176,\n",
       " 'CIDEr': 0.06145132500410184}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beam search   remove unk\n",
    "# fine-tune on artpedia, one image with multiple captions for training      shuffle\n",
    "data = torch.load('saved_models/artpedia_finetune_mulcap_shuffle.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_artpedia_test_data_loader, text_field, is_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c5499-66ae-4c92-bbc1-310bd0202fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556f0f7-0589-41f8-9952-cae1f690dd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18bfe0e8-bbed-4c5e-8886-c19de592dc24",
   "metadata": {},
   "source": [
    "## 2. semart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63624600-04f8-419c-b8f0-10c6942c8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_test_csv = pd.read_csv(\"../Dataset/SemArt/prediction_csvs/semart_test_prediction.csv\")\n",
    "sa_test_csv = sa_test_csv[sa_test_csv['predictioin']==0]\n",
    "test_roi_feats = h5py.File(\"../Dataset/SemArt/sa_test_roi.hdf5\", \"r\")\n",
    "test_img_names = np.unique(sa_test_csv['img_name'].to_numpy())\n",
    "test_img_caps_map = json.load(open('../Dataset/SemArt/test_img_caps_map.json'))\n",
    "\n",
    "dict_semart_test = SAeval_Dataset(sa_test_csv, test_img_names, test_img_caps_map, test_roi_feats, text_field, max_detections=50, lower=True, remove_punctuation=True, tokenize='spacy')\n",
    "dict_semart_test_data_loader = TorchDataLoader(dict_semart_test, batch_size=10,\n",
    "                                  collate_fn=lambda x: text_progress2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89f439-5d51-4d68-906f-6333e189342e",
   "metadata": {},
   "source": [
    "#### 2.1 semart, multiple captions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92274535-f856-404d-a5ed-04165fc33bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fc12d21fdd8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:13<00:00,  4.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.10140459597308837,\n",
       "  0.03169078168216852,\n",
       "  0.007083860979364486,\n",
       "  4.123190171219849e-07],\n",
       " 'METEOR': 0.030852755825836443,\n",
       " 'ROUGE': 0.13096962696319228,\n",
       " 'CIDEr': 0.004329042746890157}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# off-the-shelf model   ***\n",
    "data = torch.load('saved_models/saved_models_region_std/region_std_best.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a63f876-4bc2-45ed-af4c-c8bbd34b3f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fc12d21fdd8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:09<00:00,  6.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.1837182108351129,\n",
       "  0.09057445922520133,\n",
       "  0.04742767887883237,\n",
       "  0.028502222867494566],\n",
       " 'METEOR': 0.06295136197989658,\n",
       " 'ROUGE': 0.21248080847379314,\n",
       " 'CIDEr': 0.06793464689087193}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt shuffle ***\n",
    "data = torch.load('saved_models/saved_models_saft_region_std/sa_regionstd_sa_last_15epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc9a908-c10c-4269-82de-360f5789d559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fc12d21fdd8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:09<00:00,  6.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.19369142251464125,\n",
       "  0.09451746759851255,\n",
       "  0.05058007094099744,\n",
       "  0.03200999646136212],\n",
       " 'METEOR': 0.06409278986758879,\n",
       " 'ROUGE': 0.20886380803394036,\n",
       " 'CIDEr': 0.08181295820994731}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt shuffle ***\n",
    "data = torch.load('saved_models/saved_models_saft_region_std/sa_regionstd_sa_last_17epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33016bf-3d22-48b6-bb32-9854dc6f8915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fc12d21fdd8>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:09<00:00,  6.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.1844762618161031,\n",
       "  0.09035194568173129,\n",
       "  0.047122917335089914,\n",
       "  0.028681345432281263],\n",
       " 'METEOR': 0.06284682555449271,\n",
       " 'ROUGE': 0.21586449108361624,\n",
       " 'CIDEr': 0.06075225033169698}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt shuffle ***\n",
    "data = torch.load('saved_models/saved_models_saft_region_std/sa_regionstd_sa_best_9epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798a222-79a9-47d8-9def-d650e9f0e83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27d0e28-7412-479f-b1fd-4f73979150f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f2b77f55a90>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:39<00:00,  1.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.2973848290118472,\n",
       "  0.14532965320560803,\n",
       "  0.06940698793346775,\n",
       "  0.039141015893592895],\n",
       " 'METEOR': 0.08113096148741637,\n",
       " 'ROUGE': 0.23387698234426282,\n",
       " 'CIDEr': 0.07548107119948975}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt shuffle ***\n",
    "# remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_region_std/sa_regionstd_sa_best_11epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf24623b-ea13-404a-a78a-0c2a7f309dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f3f4b485438>\n",
      "multiple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evalulateion metrics: 100%|██████████| 62/62 [00:14<00:00,  4.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU': [0.2998353728530462,\n",
       "  0.1468716489820476,\n",
       "  0.07456873559596515,\n",
       "  0.04307386701642498],\n",
       " 'METEOR': 0.08242227112688057,\n",
       " 'ROUGE': 0.2251958917282386,\n",
       " 'CIDEr': 0.10360548719242094}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune on SemArt shuffle ***\n",
    "# remove <unk>\n",
    "data = torch.load('saved_models/saved_models_saft_region_std/sa_regionstd_sa_last_17epoch.pth')\n",
    "model.load_state_dict(data['state_dict'])\n",
    "evaluate_metrics(model, dict_semart_test_data_loader, text_field, mode='multiple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dfd322-2b49-4038-a04c-810be88cc974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2release",
   "language": "python",
   "name": "m2release"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
